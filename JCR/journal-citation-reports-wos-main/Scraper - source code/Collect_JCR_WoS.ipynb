{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting the records of InCites Journal Citation Reports (Web of Science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries.\n",
    "import re, csv, pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting the data from its URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_webdriver(url, is_firefox=True):\n",
    "    # Choosing the webdriver.\n",
    "    if not is_firefox:\n",
    "        # Running the PhantomJS webdriver.\n",
    "        driver = webdriver.PhantomJS()\n",
    "        driver.set_window_size(1120, 550)\n",
    "    else:\n",
    "        # Defining the option to the Firefox webdriver.\n",
    "        options = Options()\n",
    "        options.headless = True\n",
    "\n",
    "        # Running the Firefox webdriver.\n",
    "        service = Service(executable_path = \"/Users/breno/geckodriver/geckodriver\")\n",
    "        driver = webdriver.Firefox(service=service, options=options)\n",
    "\n",
    "    if is_firefox & options.headless:\n",
    "        driver.set_window_size(1120, 550)\n",
    "        driver.maximize_window()\n",
    "\n",
    "    # Getting the web page.\n",
    "    driver.get(url)\n",
    "\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate(driver):\n",
    "    # Waiting for 10 seconds.\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"mat-input-0\")))\n",
    "\n",
    "    # Authenticating with user's account data.\n",
    "    username_field = driver.find_element(By.ID, \"mat-input-0\")\n",
    "    password_field = driver.find_element(By.ID, \"mat-input-1\")\n",
    "    username_field.send_keys(\">>> VALID USER/E-MAIL <<<\")\n",
    "    password_field.send_keys(\">>> YOUR PASSWORD <<<\")\n",
    "    password_field.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Redirecting the list of journals.\n",
    "    WebDriverWait(driver, 120).until(EC.element_to_be_clickable(\n",
    "            (By.CSS_SELECTOR, \"a[title='Browse journals']\"))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    # Getting webdriver.\n",
    "    driver = init_webdriver(url)\n",
    "\n",
    "    # Authenticating the valid user.\n",
    "    authenticate(driver)\n",
    "\n",
    "    # Enabling the cookies.\n",
    "    WebDriverWait(driver, 120).until(EC.element_to_be_clickable(\n",
    "            (By.ID, \"onetrust-accept-btn-handler\"))).click()\n",
    "\n",
    "    data = []\n",
    "    flag = True\n",
    "    while flag:\n",
    "        try:\n",
    "            # Waiting to load the records.\n",
    "            WebDriverWait(driver, 120).until(EC.invisibility_of_element(\n",
    "                    (By.CSS_SELECTOR, \"div.backdrop\")))\n",
    "\n",
    "            # Defining the scraper.\n",
    "            html_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            # Getting the rows.\n",
    "            rows = html_soup.find_all(\"mat-row\")\n",
    "            for idx, row in enumerate(rows):\n",
    "                try:\n",
    "                    record = {}\n",
    "                    # Getting the columns/cells of data.\n",
    "                    cells = row.select(\"mat-cell > span\")\n",
    "\n",
    "                    # Journal name.\n",
    "                    record[\"journal_name\"] = re.sub(r\"\\s+\", \" \", cells[0].string).strip()\n",
    "\n",
    "                    # ISSN.\n",
    "                    record[\"issn\"] = re.sub(r\"\\s+\", \" \", cells[1].string).strip()\n",
    "\n",
    "                    # eISSN.\n",
    "                    record[\"e_issn\"] = re.sub(r\"\\s+\", \" \", cells[2].string).strip()\n",
    "\n",
    "                    # Category.\n",
    "                    if cells[3].select(\"span.multiple > mat-expansion-panel > div > div > span\"):\n",
    "                        items = cells[3].select(\"span.multiple > mat-expansion-panel > div > div > span\")\n",
    "                        record[\"category\"] = [re.sub(r\"\\s+\", \" \", item.string).strip() for item in items]\n",
    "                    else:\n",
    "                        record[\"category\"] = re.sub(r\"\\s+\", \" \", cells[3].string).strip()\n",
    "\n",
    "                    # Total citations.\n",
    "                    record[\"total_citations\"] = re.sub(r\"\\s+\", \" \", cells[4].string).strip()\n",
    "\n",
    "                    # 2021 JIF.\n",
    "                    record[\"impact_factor_2021\"] = re.sub(r\"\\s+\", \" \", cells[5].string).strip()\n",
    "\n",
    "                    # JIF Quartile.\n",
    "                    if cells[6].select(\"span.multiple > mat-expansion-panel > div > div > span\"):\n",
    "                        items = cells[6].select(\"span.multiple > mat-expansion-panel > div > div > span\")\n",
    "                        record[\"jif_quartile\"] = [re.sub(r\"\\s+\", \" \", item.string).strip() for item in items]\n",
    "                    else:\n",
    "                        record[\"jif_quartile\"] = re.sub(r\"\\s+\", \" \", cells[6].string).strip()\n",
    "\n",
    "                    # 2021 JCI.\n",
    "                    record[\"jci_2021\"] = re.sub(r\"\\s+\", \" \", cells[7].string).strip()\n",
    "\n",
    "                    # % of OA Gold.\n",
    "                    record[\"percent_oa_gold\"] = re.sub(r\"\\s+\", \" \", cells[8].string).strip()\n",
    "\n",
    "                    data.append(record)\n",
    "                except Exception as e:\n",
    "                    print(idx)\n",
    "                    raise e\n",
    "\n",
    "            # Waiting to load the button \"Next page\".\n",
    "            WebDriverWait(driver, 120).until(EC.element_to_be_clickable(\n",
    "                    (By.CSS_SELECTOR, \"button.mat-paginator-navigation-next\")))\n",
    "\n",
    "            # Clicking the button.\n",
    "            button = driver.find_element(By.CSS_SELECTOR, \"button.mat-paginator-navigation-next\")\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "            flag = False if button.get_attribute(\"disabled\") else True\n",
    "            if flag:\n",
    "                button.click()\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            break\n",
    "        except StaleElementReferenceException:\n",
    "            break\n",
    "\n",
    "    # Closing the webdriver.\n",
    "    driver.quit()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the URL of target page.\n",
    "url = \"https://jcr.clarivate.com/jcr/home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collecting the data.\n",
    "data = get_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of records collected.\n",
    "print(\"Number of records collected: {}.\".format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Saving the data collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the dataframe object.\n",
    "df_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data.\n",
    "df_data.replace({\"n/a\": None, \"N/A\": None}, inplace=True)\n",
    "df_data[[\"category\", \"jif_quartile\"]] = df_data[[\"category\", \"jif_quartile\"]].apply(\n",
    "    lambda x: x.apply(lambda y: tuple(y) if type(y) == list else y), axis=1)\n",
    "df_data.drop_duplicates(keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking the information about the dataset.\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the data to CSV file.\n",
    "df_data.to_csv(\"../Dataset/jcr_2021_wos.csv\", index=False, quoting=csv.QUOTE_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e313781e5f9487634688338feaea31cdeb3d0e175705036a80436c634137acb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
